{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "representative-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook creates smaller data files that only include the three most prevalent cancer types from the TCGA data\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "controlling-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the dataframes of known cancertypes (they are sorted by cancertype)\n",
    "\n",
    "# Get data file from /data folder relative to this notebook\n",
    "ipynb_dir = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "rna_file = os.path.join(ipynb_dir, '..', '..', 'data', 'RNASeq_3000MAD.csv')\n",
    "gcn_file = os.path.join(ipynb_dir, '..', '..', 'data', 'GCN_3000MAD.csv')\n",
    "dna_file = os.path.join(ipynb_dir, '..', '..', 'data', 'DNAMe_3000MAD.csv')\n",
    "\n",
    "\n",
    "rna = pd.read_csv(rna_file, index_col=0)\n",
    "gcn = pd.read_csv(gcn_file, index_col=0)\n",
    "dna = pd.read_csv(dna_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "smooth-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the cancertype labels (same order as dataframes)\n",
    "labels = np.load(os.path.join(ipynb_dir, '..', '..', 'data', 'cancertype_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fundamental-timeline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also create a dataset with only 3 cancertypes\n",
    "# only use 3 most common cancer types (BRCA : 766, KIRC : 306, LUAD : 449)\n",
    "brca = np.where(labels == 'BRCA')[0]\n",
    "kirc = np.where(labels == 'KIRC')[0]\n",
    "luad = np.where(labels == 'LUAD')[0]\n",
    "\n",
    "# Create list of the three cancer type indices\n",
    "cancer3 = [brca, kirc, luad]\n",
    "len(cancer3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recorded-mission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536 76 154\n",
      "214 30 62\n",
      "314 44 91\n",
      "1064 150 307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now get the indices 70-10-20 split, where every split has the same relative representation of cancertypes\n",
    "TRAINING_DATA_SPLIT = 0.7\n",
    "VALIDATION_DATA_SPLIT = 0.1\n",
    "PREDICT_DATA_SPLIT = 0.2\n",
    "\n",
    "all_training_ids = []\n",
    "all_validation_ids = []\n",
    "all_predict_ids = []\n",
    "\n",
    "all_training_labels = []\n",
    "all_validation_labels = []\n",
    "all_predict_labels = []\n",
    "\n",
    "label_names = [\"BRCA\", \"KIRC\", \"LUAD\"]\n",
    "\n",
    "for cancer_type in range(len(cancer3)):\n",
    "\n",
    "    nr_of_samples = len(cancer3[cancer_type])\n",
    "    nr_of_training_samples = int(TRAINING_DATA_SPLIT * nr_of_samples)\n",
    "    nr_of_validation_samples = int(VALIDATION_DATA_SPLIT * nr_of_samples)\n",
    "\n",
    "    # Random ordering of all sample id's\n",
    "    random_sample_indices = np.random.choice(a=cancer3[cancer_type], size=nr_of_samples, replace=False)\n",
    "\n",
    "    # Split into three sets of sizes\n",
    "    # [:nr_of_training_samples], [nr_of_training_samples:nr_of_validation_samples], [:nr_of_predict_samples]\n",
    "    sets = np.split(random_sample_indices,\n",
    "                    [nr_of_training_samples, (nr_of_training_samples + nr_of_validation_samples)])\n",
    "\n",
    "    training_ids = sets[0]\n",
    "    validation_ids = sets[1]\n",
    "    predict_ids = sets[2]\n",
    "\n",
    "    print(len(training_ids), len(validation_ids), len(predict_ids))\n",
    "    all_training_ids.extend(training_ids)\n",
    "    all_validation_ids.extend(validation_ids)\n",
    "    all_predict_ids.extend(predict_ids)\n",
    "    \n",
    "    all_training_labels.extend([label_names[cancer_type]] * len(training_ids))\n",
    "    all_validation_labels.extend([label_names[cancer_type]] * len(validation_ids))\n",
    "    all_predict_labels.extend([label_names[cancer_type]] * len(predict_ids))\n",
    "\n",
    "\n",
    "print(len(all_training_ids), len(all_validation_ids), len(all_predict_ids))\n",
    "len(all_predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "identified-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make selection of the dataframes based on the above ids\n",
    "rna_training_3types = rna.iloc[all_training_ids]\n",
    "gcn_training_3types = gcn.iloc[all_training_ids]\n",
    "dna_training_3types = dna.iloc[all_training_ids]\n",
    "\n",
    "rna_validation_3types = rna.iloc[all_validation_ids]\n",
    "gcn_validation_3types = gcn.iloc[all_validation_ids]\n",
    "dna_validation_3types = dna.iloc[all_validation_ids]\n",
    "\n",
    "rna_predict_3types = rna.iloc[all_predict_ids]\n",
    "gcn_predict_3types = gcn.iloc[all_predict_ids]\n",
    "dna_predict_3types = dna.iloc[all_predict_ids]\n",
    "\n",
    "save_dir = os.path.join(ipynb_dir, '..', '..', 'data', '3typesnoclamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intellectual-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "# We now have data splits for each modality, and also the labels for each split\n",
    "# For true randomness, we need to shuffle them all\n",
    "\n",
    "# Shuffle labels and dataframes for training, but keep the same order of samples and labels\n",
    "training_shuffler = np.random.permutation(len(all_training_labels))\n",
    "\n",
    "training_labels_shuffle = np.take(all_training_labels, training_shuffler)\n",
    "rna_training_shuffle = rna_training_3types.iloc[training_shuffler]\n",
    "gcn_training_shuffle = gcn_training_3types.iloc[training_shuffler]\n",
    "dna_training_shuffle = dna_training_3types.iloc[training_shuffler]\n",
    "\n",
    "np.save(os.path.join(save_dir, 'training_3types.npy'), training_labels_shuffle)\n",
    "rna_training_shuffle.to_csv(os.path.join(save_dir, 'RNASeq_3types_training.csv'))\n",
    "gcn_training_shuffle.to_csv(os.path.join(save_dir, 'GCN_3types_training.csv'))\n",
    "dna_training_shuffle.to_csv(os.path.join(save_dir, 'DNAMe_3types_training.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "multiple-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION\n",
    "# We now have data splits for each modality, and also the labels for each split\n",
    "# For true randomness, we need to shuffle them all\n",
    "\n",
    "# Shuffle labels and dataframes for validation, but keep the same order of samples and labels\n",
    "validation_shuffler = np.random.permutation(len(all_validation_labels))\n",
    "\n",
    "validation_labels_shuffle = np.take(all_validation_labels, validation_shuffler)\n",
    "rna_validation_shuffle = rna_validation_3types.iloc[validation_shuffler]\n",
    "gcn_validation_shuffle = gcn_validation_3types.iloc[validation_shuffler]\n",
    "dna_validation_shuffle = dna_validation_3types.iloc[validation_shuffler]\n",
    "\n",
    "np.save(os.path.join(save_dir, 'validation_3types.npy'), validation_labels_shuffle)\n",
    "rna_validation_shuffle.to_csv(os.path.join(save_dir, 'RNASeq_3types_validation.csv'))\n",
    "gcn_validation_shuffle.to_csv(os.path.join(save_dir, 'GCN_3types_validation.csv'))\n",
    "dna_validation_shuffle.to_csv(os.path.join(save_dir, 'DNAMe_3types_validation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "weird-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "# We now have data splits for each modality, and also the labels for each split\n",
    "# For true randomness, we need to shuffle them all\n",
    "\n",
    "# Shuffle labels and dataframes for predict, but keep the same order of samples and labels\n",
    "predict_shuffler = np.random.permutation(len(all_predict_labels))\n",
    "\n",
    "predict_labels_shuffle = np.take(all_predict_labels, predict_shuffler)\n",
    "rna_predict_shuffle = rna_predict_3types.iloc[predict_shuffler]\n",
    "gcn_predict_shuffle = gcn_predict_3types.iloc[predict_shuffler]\n",
    "dna_predict_shuffle = dna_predict_3types.iloc[predict_shuffler]\n",
    "\n",
    "np.save(os.path.join(save_dir, 'predict_3types.npy'), predict_labels_shuffle)\n",
    "rna_predict_shuffle.to_csv(os.path.join(save_dir, 'RNASeq_3types_predict.csv'))\n",
    "gcn_predict_shuffle.to_csv(os.path.join(save_dir, 'GCN_3types_predict.csv'))\n",
    "dna_predict_shuffle.to_csv(os.path.join(save_dir, 'DNAMe_3types_predict.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
