{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mord import OrdinalRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ctype_train_file = \"/home/bram/jointomicscomp/data/BRCA/BRCA_GE_train.npy\"\n",
    "y_ctype_train_file = \"/home/bram/jointomicscomp/data/BRCA/BRCA_ME_train.npy\"\n",
    "x_ctype_valid_file = \"/home/bram/jointomicscomp/data/BRCA/BRCA_GE_valid.npy\"\n",
    "y_ctype_valid_file = \"/home/bram/jointomicscomp/data/BRCA/BRCA_ME_valid.npy\"\n",
    "x_ctype_test_file = \"/home/bram/jointomicscomp/data/BRCA/BRCA_GE_test.npy\"\n",
    "y_ctype_test_file = \"/home/bram/jointomicscomp/data/BRCA/BRCA_ME_test.npy\"\n",
    "\n",
    "# For latent feature extraction\n",
    "GEtrainctype = np.load(x_ctype_train_file)\n",
    "GEvalidctype = np.load(x_ctype_valid_file)\n",
    "GEtestctype = np.load(x_ctype_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load(\"/home/bram/jointomicscomp/data/BRCA/BRCA_train_stageType.npy\")\n",
    "y_valid = np.load(\"/home/bram/jointomicscomp/data/BRCA/BRCA_valid_stageType.npy\")\n",
    "y_test = np.load(\"/home/bram/jointomicscomp/data/BRCA/BRCA_test_stageType.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z1 for GE and z2 for ME\n",
    "z_moe = np.load(\"/home/bram/jointomicscomp/results/trained MVAE task 2/MoE/task2_z.npy\")\n",
    "z_poe = np.load(\"//home/bram/jointomicscomp/results/trained MVAE task 2/PoE/task2_z.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(687, 128)\n",
      "(77, 128)\n",
      "(85, 128)\n",
      "(687, 128)\n",
      "(77, 128)\n",
      "(85, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create labels from stageTypes and stageTypes\n",
    "latent_train1 = z_moe[:len(GEtrainctype)]\n",
    "latent_valid1 = z_moe[len(latent_train1):(len(GEtrainctype) + len(GEvalidctype))]\n",
    "latent_test1 = z_moe[(len(latent_train1) + len(latent_valid1)):(len(GEtrainctype) + len(GEvalidctype) + len(GEtestctype))]\n",
    "\n",
    "print(latent_train1.shape)\n",
    "print(latent_valid1.shape)\n",
    "print(latent_test1.shape)\n",
    "\n",
    "latent_train2 = z_poe[:len(GEtrainctype)]\n",
    "latent_valid2 = z_poe[len(latent_train2):(len(GEtrainctype) + len(GEvalidctype))]\n",
    "latent_test2 = z_poe[(len(latent_train2) + len(latent_valid2)):(len(GEtrainctype) + len(GEvalidctype) + len(GEtestctype))]\n",
    "\n",
    "print(latent_train2.shape)\n",
    "print(latent_valid2.shape)\n",
    "print(latent_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(764,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((y_train, y_valid)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies from Mixture-of-Experts\n",
      "Accuracies:  [54.12, 54.12, 55.29, 54.12, 57.65, 57.65, 57.65, 57.65, 57.65, 57.65]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracies from Mixture-of-Experts\")\n",
    "accuracies = []\n",
    "alphas = np.array([1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1.0, 2.0, 5.0, 10., 20.])\n",
    "for i, a in enumerate(alphas):\n",
    "    model = OrdinalRidge(alpha=a, fit_intercept=True, normalize=False, random_state=1)\n",
    "\n",
    "    # Train\n",
    "    model.fit(np.vstack((latent_train1, latent_valid1)), np.concatenate((y_train, y_valid)))\n",
    "\n",
    "    y_pred = model.predict(latent_test1)\n",
    "\n",
    "    n = len(y_pred)\n",
    "    correct = 0\n",
    "\n",
    "    for t, p in zip(y_test, y_pred):\n",
    "        if t == p:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = (correct / n) * 100\n",
    "    accuracies.append(round(accuracy, 2))\n",
    "\n",
    "print(\"Accuracies: \", accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies from Product-of-Experts\n",
      "Accuracies:  [51.76, 52.94, 58.82, 57.65, 57.65, 57.65, 57.65, 57.65, 57.65, 57.65]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracies from Product-of-Experts\")\n",
    "accuracies = []\n",
    "alphas = np.array([1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1.0, 2.0, 5.0, 10., 20.])\n",
    "for i, a in enumerate(alphas):\n",
    "    model = OrdinalRidge(alpha=a, fit_intercept=True, normalize=False, random_state=1)\n",
    "\n",
    "    # Train\n",
    "    model.fit(np.vstack((latent_train2, latent_valid2)), np.concatenate((y_train, y_valid)))\n",
    "\n",
    "    y_pred = model.predict(latent_test2)\n",
    "\n",
    "    n = len(y_pred)\n",
    "    correct = 0\n",
    "\n",
    "    for t, p in zip(y_test, y_pred):\n",
    "        if t == p:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = (correct / n) * 100\n",
    "    accuracies.append(round(accuracy, 2))\n",
    "\n",
    "print(\"Accuracies: \", accuracies)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}