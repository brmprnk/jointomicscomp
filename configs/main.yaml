GLOBAL_PARAMS:
  name: "default_name"
  data_path: 'example'

MVAE:
  # Flags
  mixture: false  # Flag that indicates if the MVAE uses Mixture-of-Experts instead of Product-of-Experts
  plot: false     # Flag for plotting training and validation losses (loss, recon loss and KL loss)
  cancer3: false  # Flag for using smaller dataset with only 3 cancer types

  # Hyperparameters
  latent_dim: 128
  batch_size: 256
  epochs: 1
  lr: 0.0001

  # Other parameters
  log_interval: 5
  cuda: false
  random_seed: 1